{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "import numpy as np"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.289278700Z",
     "start_time": "2024-11-28T03:50:16.219905800Z"
    }
   },
   "id": "ddf7c3df246b87c5",
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of dataset in characters: 1115393\n"
     ]
    }
   ],
   "source": [
    "with open('input.txt', 'r', encoding='utf-8') as f:\n",
    "    text = f.read()\n",
    "    \n",
    "print('length of dataset in characters: {}'.format(len(text)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.316913300Z",
     "start_time": "2024-11-28T03:50:16.297273100Z"
    }
   },
   "id": "8b1a4e78e4b8ceaf",
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You\n"
     ]
    }
   ],
   "source": [
    "print(text[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.346897300Z",
     "start_time": "2024-11-28T03:50:16.313339100Z"
    }
   },
   "id": "7733524e7d5fa4e8",
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "source": [
    "# create a mapping from character to integer "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c37c8b0ae8a9796"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !$&',-.3:;?ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz\n",
      "65\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(chars))\n",
    "print(vocab_size)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.405835900Z",
     "start_time": "2024-11-28T03:50:16.325879400Z"
    }
   },
   "id": "422e7d662a6138c6",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]\n",
      "['h', 'e', 'l', 'l', 'o', ' ', 't', 'h', 'e', 'r', 'e']\n"
     ]
    }
   ],
   "source": [
    "stoi = {ch:i for i,ch in enumerate(chars)}\n",
    "itos = {i:ch for i,ch in enumerate(chars)}\n",
    "encode = lambda s: [stoi[c] for c in s]\n",
    "decode = lambda l: [itos[i] for i in l]\n",
    "\n",
    "print(encode('hello there'))\n",
    "print(decode([46, 43, 50, 50, 53, 1, 58, 46, 43, 56, 43]))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.407880600Z",
     "start_time": "2024-11-28T03:50:16.359893300Z"
    }
   },
   "id": "199b61a2cb57aef1",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import torch"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.521768800Z",
     "start_time": "2024-11-28T03:50:16.412863Z"
    }
   },
   "id": "6eac65d8afc9f47d",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1115393]) torch.int64\n",
      "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58, 47, 64, 43, 52, 10,  0, 14, 43, 44,\n",
      "        53, 56, 43,  1, 61, 43,  1, 54, 56, 53, 41, 43, 43, 42,  1, 39, 52, 63,\n",
      "         1, 44, 59, 56, 58, 46, 43, 56,  6,  1, 46, 43, 39, 56,  1, 51, 43,  1,\n",
      "        57, 54, 43, 39, 49,  8,  0,  0, 13, 50, 50, 10,  0, 31, 54, 43, 39, 49,\n",
      "         6,  1, 57, 54, 43, 39, 49,  8,  0,  0, 18, 47, 56, 57, 58,  1, 15, 47,\n",
      "        58, 47, 64, 43, 52, 10,  0, 37, 53, 59])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(text), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:100])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.801610500Z",
     "start_time": "2024-11-28T03:50:16.530786200Z"
    }
   },
   "id": "ad46c9624460b2f8",
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "n = int(0.9*len(data))\n",
    "train_data = data[:n]\n",
    "test_data = data[n:]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.816640900Z",
     "start_time": "2024-11-28T03:50:16.797647500Z"
    }
   },
   "id": "393e26fd6302fdd",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "tensor([18, 47, 56, 57, 58,  1, 15, 47, 58])"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.870160300Z",
     "start_time": "2024-11-28T03:50:16.807636700Z"
    }
   },
   "id": "53198ad9ad4ae06a",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "when input is tensor([18]), target is 47\n",
      "when input is tensor([18, 47]), target is 56\n",
      "when input is tensor([18, 47, 56]), target is 57\n",
      "when input is tensor([18, 47, 56, 57]), target is 58\n",
      "when input is tensor([18, 47, 56, 57, 58]), target is 1\n",
      "when input is tensor([18, 47, 56, 57, 58,  1]), target is 15\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15]), target is 47\n",
      "when input is tensor([18, 47, 56, 57, 58,  1, 15, 47]), target is 58\n"
     ]
    }
   ],
   "source": [
    "# 理解一下输入输出\n",
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(\"when input is {}, target is {}\".format(context, target))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.872163Z",
     "start_time": "2024-11-28T03:50:16.834155800Z"
    }
   },
   "id": "51e202af8928dbda",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[40, 56, 53, 61, 57,  0, 40, 53],\n",
      "        [59, 54, 54, 53, 57, 43, 42,  1],\n",
      "        [ 1, 46, 43, 39, 42,  8,  0,  0],\n",
      "        [39, 63,  1, 46, 39, 42,  1, 61]])\n",
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[56, 53, 61, 57,  0, 40, 53, 59],\n",
      "        [54, 54, 53, 57, 43, 42,  1, 63],\n",
      "        [46, 43, 39, 42,  8,  0,  0, 16],\n",
      "        [63,  1, 46, 39, 42,  1, 61, 43]])\n",
      "when context is tensor([40]), target is 56\n",
      "when context is tensor([40, 56]), target is 53\n",
      "when context is tensor([40, 56, 53]), target is 61\n",
      "when context is tensor([40, 56, 53, 61]), target is 57\n",
      "when context is tensor([40, 56, 53, 61, 57]), target is 0\n",
      "when context is tensor([40, 56, 53, 61, 57,  0]), target is 40\n",
      "when context is tensor([40, 56, 53, 61, 57,  0, 40]), target is 53\n",
      "when context is tensor([40, 56, 53, 61, 57,  0, 40, 53]), target is 59\n",
      "when context is tensor([59]), target is 54\n",
      "when context is tensor([59, 54]), target is 54\n",
      "when context is tensor([59, 54, 54]), target is 53\n",
      "when context is tensor([59, 54, 54, 53]), target is 57\n",
      "when context is tensor([59, 54, 54, 53, 57]), target is 43\n",
      "when context is tensor([59, 54, 54, 53, 57, 43]), target is 42\n",
      "when context is tensor([59, 54, 54, 53, 57, 43, 42]), target is 1\n",
      "when context is tensor([59, 54, 54, 53, 57, 43, 42,  1]), target is 63\n",
      "when context is tensor([1]), target is 46\n",
      "when context is tensor([ 1, 46]), target is 43\n",
      "when context is tensor([ 1, 46, 43]), target is 39\n",
      "when context is tensor([ 1, 46, 43, 39]), target is 42\n",
      "when context is tensor([ 1, 46, 43, 39, 42]), target is 8\n",
      "when context is tensor([ 1, 46, 43, 39, 42,  8]), target is 0\n",
      "when context is tensor([ 1, 46, 43, 39, 42,  8,  0]), target is 0\n",
      "when context is tensor([ 1, 46, 43, 39, 42,  8,  0,  0]), target is 16\n",
      "when context is tensor([39]), target is 63\n",
      "when context is tensor([39, 63]), target is 1\n",
      "when context is tensor([39, 63,  1]), target is 46\n",
      "when context is tensor([39, 63,  1, 46]), target is 39\n",
      "when context is tensor([39, 63,  1, 46, 39]), target is 42\n",
      "when context is tensor([39, 63,  1, 46, 39, 42]), target is 1\n",
      "when context is tensor([39, 63,  1, 46, 39, 42,  1]), target is 61\n",
      "when context is tensor([39, 63,  1, 46, 39, 42,  1, 61]), target is 43\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(509)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    \n",
    "    data = train_data if split == 'train' else test_data\n",
    "    ix = torch.randint(len(data) - block_size, (batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    ## 注意，对每一条input sequence, y不是只有下一个token，y同样也是一个sequence\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    \n",
    "    return x,y\n",
    "\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print(\"inputs:\")\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "\n",
    "print(\"inputs:\")\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(\"when context is {}, target is {}\".format(context, target))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T03:50:16.942088300Z",
     "start_time": "2024-11-28T03:50:16.862136Z"
    }
   },
   "id": "a200ccc4167beb68",
   "execution_count": 13
  },
  {
   "cell_type": "markdown",
   "source": [
    "nn.Embedding将输入的整数序列装换成密集向量表达:\n",
    "* 第一个参数num_embeddings：词的个数\n",
    "* 第二个参数embedding_dim：embedding的维度"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4088234e25917ce1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Bigram Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4d1ca94e0a9e9c1c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "torch中的dim，代表对这个维度的所有元素进行操作\n",
    "* 比如torch.cat((idx, next_idx), dim = 1)，就是在1维进行concat\n",
    "* torch.sum(a, 1, keepdim = True)，就是将1维都加起来"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8528045a54bebbb"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 65])\n",
      "tensor([[ 0.0282, -0.4387,  1.0534,  ..., -0.3558, -0.1233,  1.1046],\n",
      "        [ 0.9527,  0.3031, -1.4552,  ..., -0.2864, -0.1493, -1.6743],\n",
      "        [-1.0090,  0.5156, -0.1046,  ...,  1.4170,  1.4547, -0.4403],\n",
      "        ...,\n",
      "        [ 1.1371, -0.4484,  0.5714,  ...,  0.4964, -0.1508, -0.8930],\n",
      "        [ 0.0282, -0.4387,  1.0534,  ..., -0.3558, -0.1233,  1.1046],\n",
      "        [ 0.3090,  0.7605,  0.5701,  ...,  0.6129,  1.1609,  0.0365]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "\n",
      "UBJ&BqmtEv&:Scz o&w-kDmtq!Xx:lQghTU!sHgfhZkZ.ZN$Sza!fRizMzqTuoA,Dx?-AQXcgvzWszOqmaLHaBK:$X&:AKAsiw-z\n"
     ]
    }
   ],
   "source": [
    "class BigramLanguageModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)  #(B, T, C)\n",
    "        \n",
    "        \n",
    "    def forward(self, idx, targets=None):\n",
    "        # idx和target就是前面的xb,yb,所有都是(B,T)的\n",
    "        # 经过embedding之后变成：(B,T,C)\n",
    "        logits = self.token_embedding_table(idx)\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B, T, C = logits.shape\n",
    "            logits = logits.view(B*T,C)\n",
    "            targets = targets.view(B*T)\n",
    "            loss = F.cross_entropy(logits, targets)\n",
    "        \n",
    "        return logits, loss\n",
    "\n",
    "    def generate(self, idx, max_new_tokens):\n",
    "        \n",
    "        for _ in range(max_new_tokens):\n",
    "            logits, loss = self(idx)  # calling self.forward\n",
    "            logits = logits[:, -1, :]  # (B,C)\n",
    "            # 生成概率\n",
    "            probs = F.softmax(logits, dim = -1)  # (B, C)\n",
    "            # 根据概率sample\n",
    "            next_idx = torch.multinomial(probs, num_samples=1)  # (B,1)\n",
    "            idx = torch.cat((idx, next_idx), dim = 1)\n",
    "        \n",
    "        return idx \n",
    "    \n",
    "    \n",
    "bigram_model = BigramLanguageModel(vocab_size)\n",
    "logits, loss = bigram_model(xb, yb)\n",
    "\n",
    "print(logits.shape)\n",
    "print(logits)\n",
    "\n",
    "print(''.join(decode(bigram_model.generate(idx = torch.zeros((1,1), dtype = torch.long), max_new_tokens = 100)[0].tolist())))\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T06:43:48.893107700Z",
     "start_time": "2024-11-28T06:43:48.844170900Z"
    }
   },
   "id": "362595e54dc72963",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.470495223999023\n"
     ]
    }
   ],
   "source": [
    "optimizer = torch.optim.AdamW(bigram_model.parameters(), lr = 1e-3)\n",
    "\n",
    "batch_size = 32\n",
    "\n",
    "for steps in range(200):\n",
    "    xb, yb = get_batch('train')\n",
    "    logits, loss = bigram_model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "print(loss.item())\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T06:44:37.530950500Z",
     "start_time": "2024-11-28T06:44:36.852269Z"
    }
   },
   "id": "ef8eb6034f5a0a91",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ";qNxyzQNnCOBySy!kwaFMZmCjDmLcbSGNHMoLYK..GIoeoO3'bMpsoDTZgSkAGUdilOLEBevwRh;bXYPevnt-ajvaHBN 'oLqJAFaOr?rG!owaHDkDp,V?lO&OoinWKh.MgS&:?3fBrS\n",
      "AJevwqb!Fmk:t;fRxDkiEB\n",
      ";NJrOW$ktw;dMH\n",
      "gLiwjbgsu.JeHEwukeZINvai3xPdLEhiE mtXPabpZAB,OlOfDi&ci3ArsjPCfCce\n",
      ";E:gUq\n",
      "fcko&:!QNXTYTF3E3WwPAjJ,hAIBZgYN fnRJaYkdkBat,TKIzGP3'o?KnvaNLQSb,TX\n",
      "!o.kuonGPe;JfURu:pDf'U;3PeOntuW$TZiHgHshkByLM\n",
      ";JVamYXZLBs?UJNu'atQNLR&bwiR\n",
      "gvw!fiyp:dVaYfbZUl?In\n",
      "uPgRr?IBQMKiUrs::yqExUKp dwKEY'eaFORhVpXoDgMwlXVaF.q;&?:t\n",
      "VbOsinw&tTeVjKqDZLsxLx3t\n"
     ]
    }
   ],
   "source": [
    "print(''.join(decode(bigram_model.generate(idx = torch.zeros((1, 1), dtype=torch.long), max_new_tokens=500)[0].tolist())))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T06:44:40.625110900Z",
     "start_time": "2024-11-28T06:44:40.481164100Z"
    }
   },
   "id": "c5bd8e1f9eef9695",
   "execution_count": 23
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Self-Attention"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "49580b60829be50d"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 0., 0.],\n",
      "        [1., 1., 0.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1.0000, 0.0000, 0.0000],\n",
      "        [0.5000, 0.5000, 0.0000],\n",
      "        [0.3333, 0.3333, 0.3333]])\n",
      "tensor([[4., 9.],\n",
      "        [0., 2.],\n",
      "        [8., 0.]])\n",
      "tensor([[4.0000, 9.0000],\n",
      "        [2.0000, 5.5000],\n",
      "        [4.0000, 3.6667]])\n"
     ]
    }
   ],
   "source": [
    "a = torch.tril(torch.ones(3,3))\n",
    "print(a)\n",
    "\n",
    "a = a / torch.sum(a, 1, keepdim = True)\n",
    "print(a)\n",
    "\n",
    "b =  torch.randint(0,10,(3,2)).float()\n",
    "print(b)\n",
    "\n",
    "c = a @ b\n",
    "print(c)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T07:10:27.326594300Z",
     "start_time": "2024-11-28T07:10:27.290614100Z"
    }
   },
   "id": "5b7b9c012aa4ff59",
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "torch.Size([4, 8, 2])"
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(1004)\n",
    "B, T, C = 4, 8, 2\n",
    "x = torch.randn(B,T,C)\n",
    "\n",
    "x.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T07:13:51.642481800Z",
     "start_time": "2024-11-28T07:13:51.596508900Z"
    }
   },
   "id": "38a39faff70f475f",
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.6492, -0.6707],\n",
      "         [-1.1352, -1.1039],\n",
      "         [-0.8041, -0.7152],\n",
      "         [-0.4538, -0.2215],\n",
      "         [ 0.0567, -0.3237],\n",
      "         [-0.0317, -0.0122],\n",
      "         [ 0.0367, -0.0481],\n",
      "         [ 0.0413,  0.0769]],\n",
      "\n",
      "        [[-0.6925,  0.9243],\n",
      "         [ 0.1176,  1.0500],\n",
      "         [ 0.0685,  1.1512],\n",
      "         [ 0.0457,  0.8229],\n",
      "         [-0.1824,  0.6395],\n",
      "         [-0.0724,  0.6345],\n",
      "         [ 0.1508,  0.6462],\n",
      "         [ 0.1089,  0.7985]],\n",
      "\n",
      "        [[ 0.3470,  0.9166],\n",
      "         [-0.3207,  0.8867],\n",
      "         [ 0.0820,  0.6172],\n",
      "         [-0.0962,  0.9935],\n",
      "         [-0.0474,  0.9025],\n",
      "         [-0.2767,  0.8389],\n",
      "         [-0.3780,  0.7107],\n",
      "         [-0.3710,  0.7142]],\n",
      "\n",
      "        [[ 0.5993,  1.3617],\n",
      "         [ 1.1844,  0.6525],\n",
      "         [ 0.6642,  0.3576],\n",
      "         [ 0.8054,  0.0113],\n",
      "         [ 0.5579,  0.0457],\n",
      "         [ 0.4041, -0.2544],\n",
      "         [ 0.1834, -0.1784],\n",
      "         [ 0.0139, -0.3001]]])\n"
     ]
    }
   ],
   "source": [
    "# version 2: matrix multiplication for a weighted aggregation\n",
    "wei = torch.tril(torch.ones(T, T))\n",
    "wei = wei / wei.sum(1, keepdim = True)\n",
    "xbow = wei @ x \n",
    "print(xbow)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T07:17:01.335029800Z",
     "start_time": "2024-11-28T07:17:01.322037700Z"
    }
   },
   "id": "b01121e8b5e1d56c",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "True"
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# version 3: use softmax \n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = torch.zeros(T, T)\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = 1)\n",
    "xbow2 = wei @ x \n",
    "torch.allclose(xbow2, xbow)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T07:23:40.234664700Z",
     "start_time": "2024-11-28T07:23:40.193690Z"
    }
   },
   "id": "85adb5847cbcb89d",
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 16])\n"
     ]
    }
   ],
   "source": [
    "# version 4: masked self-attention\n",
    "\n",
    "torch.manual_seed(1823)\n",
    "B, T, C = 4, 8, 32\n",
    "x = torch.randn(B, T, C)\n",
    "\n",
    "# single head self-attention\n",
    "\n",
    "head_size = 16\n",
    "key = nn.Linear(C, head_size, bias=False)\n",
    "query = nn.Linear(C, head_size, bias=False)\n",
    "value = nn.Linear(C, head_size, bias=False)\n",
    "\n",
    "k = key(x)\n",
    "q = query(x)\n",
    "\n",
    "wei = q @ k.transpose(-2, -1)  # (B, T, 16) @ (B, 16, T) -> (B, T, T)\n",
    "tril = torch.tril(torch.ones(T, T))\n",
    "wei = wei.masked_fill(tril == 0, float('-inf'))\n",
    "wei = F.softmax(wei, dim = -1)\n",
    "\n",
    "v = value(x)\n",
    "out = wei @ v \n",
    "print(out.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T07:30:47.207583800Z",
     "start_time": "2024-11-28T07:30:47.177632400Z"
    }
   },
   "id": "42b6322cd9d5313e",
   "execution_count": 37
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Layer Norm"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "63d530a0ef559c85"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100])\n"
     ]
    }
   ],
   "source": [
    "class LayerNorm1d:\n",
    "    \n",
    "    def __init__(self, dim, eps=1e-5, momentum=0.1):\n",
    "        self.eps = eps\n",
    "        self.gamma = torch.ones(dim)\n",
    "        self.beta = torch.zeros(dim)\n",
    "    \n",
    "    def __call__(self, x):\n",
    "        xmean = x.mean(1, keepdim=True)\n",
    "        xvar = x.var(1, keepdim=True)\n",
    "        xhat = (x-xmean) / torch.sqrt(xvar + self.eps) \n",
    "        self.out = self.gamma * xhat + self.beta\n",
    "        return self.out\n",
    "    \n",
    "    def parameters(self):\n",
    "        return [self.gamma, self.beta]\n",
    "\n",
    "torch.manual_seed(211)\n",
    "module = LayerNorm1d(100)\n",
    "# batch size 32, 100 dimensional vectors\n",
    "x = torch.randn(32, 100)\n",
    "x = module(x)\n",
    "print(x.shape)\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T09:12:17.010395100Z",
     "start_time": "2024-11-28T09:12:16.981776700Z"
    }
   },
   "id": "336c8c68db18afbe",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(0.1098), tensor(0.9865))"
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean, std of one feature across all batch inputs\n",
    "x[:,0].mean(), x[:, 0].std()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T09:14:57.661990300Z",
     "start_time": "2024-11-28T09:14:57.645916100Z"
    }
   },
   "id": "866de2551667cd15",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "(tensor(-9.5367e-09), tensor(1.0000))"
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean std of a single input from the batch of its features \n",
    "x[0, :].mean(), x[0,:].std()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-11-28T09:15:45.463038200Z",
     "start_time": "2024-11-28T09:15:45.451051900Z"
    }
   },
   "id": "94114eb5c6b43e13",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Full code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ed7af81752d6d1b"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a4065d431fe5d355"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "630f6f97be2783df"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
